{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Comparing CNN's and RNN's for time series classification on the Human Activity Recognition dataset"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Importing libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import keras\n",
      "from os import listdir\n",
      "from utilities import *\n",
      "from sklearn.model_selection import train_test_split\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Defining key variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_steps=128\n",
      "channels=9\n",
      "batch=600"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Loading the train and test data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This module reads data from folders and arranges it into (data_points,time_steps,channels) format."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loading train and test data\n",
      "path=\"UCI HAR Dataset/UCI HAR Dataset/\"\n",
      "features=[x for x in listdir(path+\"train/Inertial Signals\") if '~' not in x]\n",
      "features.sort()\n",
      "features1=[x for x in listdir(path+\"test/Inertial Signals\") if '~' not in x]\n",
      "features1.sort()\n",
      "\n",
      "y_train=np.loadtxt(path+\"train/y_train.txt\")-1\n",
      "y_test=np.loadtxt(path+\"test/y_test.txt\")-1\n",
      "\n",
      "train_data=np.zeros((y_train.shape[0],time_steps,channels))\n",
      "test_data=np.zeros((y_test.shape[0],time_steps,channels))\n",
      "\n",
      "for i in range(len(features)):\n",
      "    tr_data=np.loadtxt(path+'/train/Inertial Signals/'+features[i])\n",
      "    te_data=np.loadtxt(path+'/test/Inertial Signals/'+features1[i])\n",
      "    \n",
      "    train_data[:,:,i]=tr_data\n",
      "    test_data[:,:,i]=te_data\n",
      "    \n",
      "print(train_data.shape)\n",
      "print(test_data.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7352, 128, 9)\n",
        "(2947, 128, 9)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7352, 128, 9)\n",
        "(2947, 128, 9)\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is another way to load the data which uses a custom built \"read_data\" function from the utlities.py file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data, y_train, list_ch_train = read_data(data_path=\"data/\", split=\"train\") # train\n",
      "test_data, y_test, list_ch_test = read_data(data_path=\"data/\", split=\"test\") # test\n",
      "\n",
      "y_train=np.array([x-1 for x in y_train])\n",
      "y_test=np.array([x-1 for x in y_test])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Normalizing the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Two different techniques for normalizing the data. The first normalizes data for each of the 9 channels. The second one normalizies data for each time step across the 9 channels. Prefer using the first one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here,try two different methods of normalization.\n",
      "# First way: Normalize for each channels\n",
      "for i in range(channels):\n",
      "    train_data[:,:,i]=(train_data[:,:,i]-np.mean(train_data[:,:,i]))/np.std(train_data[:,:,i])\n",
      "    test_data[:,:,i]=(test_data[:,:,i]-np.mean(test_data[:,:,i]))/np.std(test_data[:,:,i])\n",
      "    \n",
      "# Second way: As done online\n",
      "# train_data=(train_data-np.mean(train_data,axis=0)[None,:,:])/np.std(train_data,axis=0)[None,:,:]\n",
      "# test_data=(test_data-np.mean(test_data,axis=0)[None,:,:])/np.std(test_data,axis=0)[None,:,:]\n",
      "\n",
      "print(train_data.shape)\n",
      "print(test_data.shape)\n",
      "print(y_train.shape)\n",
      "print(y_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7352, 128, 9)\n",
        "(2947, 128, 9)\n",
        "(7352,)\n",
        "(2947,)\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Splitting into train and validation set using stratifed split"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Splits the train data into train and validation datasets using stratified splitting so that ratio of each class in both datasets is equal."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train-Val split\n",
      "x_train,x_val,y_train,y_val=train_test_split(train_data,y_train,stratify=y_train,random_state=123)\n",
      "print(y_train.shape)\n",
      "print(y_train[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5514,)\n",
        "5.0\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "One-hot encoding of data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Onehot encodes the labels. There are a total of 6 classes (0-5). So,for a label of 1,the onehot encoding is [0,1,0,0,0,0]."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.utils import to_categorical\n",
      "# One hot encoding of labels\n",
      "y_train=to_categorical(y_train)\n",
      "y_val=to_categorical(y_val)\n",
      "y_test=to_categorical(y_test)\n",
      "\n",
      "print(y_train.shape)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5514, 6)\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Convolutional Neural Network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This module defines a convolutional neural network whose structure can be seen using model.summary() function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.layers import Dense,Dropout,Conv1D,BatchNormalization,MaxPool1D,Flatten\n",
      "from keras.models import Sequential\n",
      "from keras.callbacks import History\n",
      "\n",
      "history=History()\n",
      "\n",
      "model=Sequential()\n",
      "model.add(Conv1D(filters=18,kernel_size=2,strides=1,padding='same',activation='relu',input_shape=(time_steps,channels)))\n",
      "model.add(MaxPool1D(pool_size=2,strides=2,padding='same'))\n",
      "model.add(Conv1D(filters=36,kernel_size=2,strides=1,padding='same',activation='relu'))\n",
      "model.add(MaxPool1D(pool_size=2,strides=2,padding='same'))\n",
      "model.add(Conv1D(filters=72,kernel_size=2,strides=1,padding='same',activation='relu'))\n",
      "model.add(MaxPool1D(pool_size=2,strides=2,padding='same'))\n",
      "model.add(Conv1D(filters=144,kernel_size=2,strides=1,padding='same',activation='relu'))\n",
      "model.add(MaxPool1D(pool_size=2,strides=2,padding='same'))\n",
      "model.add(Flatten())\n",
      "model.add(Dropout(0.5))\n",
      "model.add(Dense(6,activation='softmax'))\n",
      "\n",
      "print(model.summary())\n",
      "adam=keras.optimizers.Adam(lr=0.0001)\n",
      "\n",
      "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=adam)\n",
      "history=model.fit(x_train,y_train,batch_size=600,epochs=100,verbose=2,validation_data=(x_val,y_val),shuffle=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv1d_13 (Conv1D)           (None, 128, 18)           342       \n",
        "_________________________________________________________________\n",
        "max_pooling1d_13 (MaxPooling (None, 64, 18)            0         \n",
        "_________________________________________________________________\n",
        "conv1d_14 (Conv1D)           (None, 64, 36)            1332      \n",
        "_________________________________________________________________\n",
        "max_pooling1d_14 (MaxPooling (None, 32, 36)            0         \n",
        "_________________________________________________________________\n",
        "conv1d_15 (Conv1D)           (None, 32, 72)            5256      \n",
        "_________________________________________________________________\n",
        "max_pooling1d_15 (MaxPooling (None, 16, 72)            0         \n",
        "_________________________________________________________________\n",
        "conv1d_16 (Conv1D)           (None, 16, 144)           20880     \n",
        "_________________________________________________________________\n",
        "max_pooling1d_16 (MaxPooling (None, 8, 144)            0         \n",
        "_________________________________________________________________\n",
        "flatten_4 (Flatten)          (None, 1152)              0         \n",
        "_________________________________________________________________\n",
        "dropout_4 (Dropout)          (None, 1152)              0         \n",
        "_________________________________________________________________\n",
        "dense_17 (Dense)             (None, 6)                 6918      \n",
        "=================================================================\n",
        "Total params: 34,728\n",
        "Trainable params: 34,728\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "None\n",
        "Train on 5514 samples, validate on 1838 samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1/100\n",
        " - 3s - loss: 1.8113 - acc: 0.1846 - val_loss: 1.7103 - val_acc: 0.1578\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/100\n",
        " - 1s - loss: 1.7199 - acc: 0.1861 - val_loss: 1.6410 - val_acc: 0.1687\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/100\n",
        " - 1s - loss: 1.6589 - acc: 0.1984 - val_loss: 1.5906 - val_acc: 0.1763\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/100\n",
        " - 1s - loss: 1.6116 - acc: 0.2292 - val_loss: 1.5455 - val_acc: 0.3319\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/100\n",
        " - 1s - loss: 1.5631 - acc: 0.2818 - val_loss: 1.4995 - val_acc: 0.3732\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 6/100\n",
        " - 1s - loss: 1.5121 - acc: 0.3350 - val_loss: 1.4484 - val_acc: 0.3885\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/100\n",
        " - 1s - loss: 1.4664 - acc: 0.3725 - val_loss: 1.3920 - val_acc: 0.4249\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 8/100\n",
        " - 1s - loss: 1.4005 - acc: 0.4213 - val_loss: 1.3302 - val_acc: 0.5076\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/100\n",
        " - 1s - loss: 1.3421 - acc: 0.4536 - val_loss: 1.2680 - val_acc: 0.5446\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 10/100\n",
        " - 1s - loss: 1.2836 - acc: 0.5011 - val_loss: 1.2072 - val_acc: 0.5925\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 11/100\n",
        " - 1s - loss: 1.2246 - acc: 0.5368 - val_loss: 1.1515 - val_acc: 0.6295\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 12/100\n",
        " - 1s - loss: 1.1750 - acc: 0.5776 - val_loss: 1.0998 - val_acc: 0.6632\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 13/100\n",
        " - 1s - loss: 1.1283 - acc: 0.6026 - val_loss: 1.0510 - val_acc: 0.6823\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 14/100\n",
        " - 1s - loss: 1.0768 - acc: 0.6302 - val_loss: 1.0035 - val_acc: 0.7149\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 15/100\n",
        " - 1s - loss: 1.0294 - acc: 0.6532 - val_loss: 0.9567 - val_acc: 0.7356\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 16/100\n",
        " - 1s - loss: 0.9769 - acc: 0.6902 - val_loss: 0.9087 - val_acc: 0.7666\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 17/100\n",
        " - 1s - loss: 0.9397 - acc: 0.6942 - val_loss: 0.8596 - val_acc: 0.7715\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 18/100\n",
        " - 1s - loss: 0.8942 - acc: 0.7144 - val_loss: 0.8098 - val_acc: 0.7960\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 19/100\n",
        " - 1s - loss: 0.8374 - acc: 0.7339 - val_loss: 0.7596 - val_acc: 0.8107\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 20/100\n",
        " - 1s - loss: 0.7919 - acc: 0.7494 - val_loss: 0.7101 - val_acc: 0.8226\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 21/100\n",
        " - 1s - loss: 0.7425 - acc: 0.7662 - val_loss: 0.6623 - val_acc: 0.8400\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 22/100\n",
        " - 1s - loss: 0.6897 - acc: 0.7749 - val_loss: 0.6163 - val_acc: 0.8493\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 23/100\n",
        " - 1s - loss: 0.6501 - acc: 0.7818 - val_loss: 0.5742 - val_acc: 0.8558\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 24/100\n",
        " - 1s - loss: 0.6122 - acc: 0.7992 - val_loss: 0.5337 - val_acc: 0.8700\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 25/100\n",
        " - 2s - loss: 0.5710 - acc: 0.8108 - val_loss: 0.4976 - val_acc: 0.8754\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 26/100\n",
        " - 2s - loss: 0.5336 - acc: 0.8186 - val_loss: 0.4646 - val_acc: 0.8792\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 27/100\n",
        " - 2s - loss: 0.4954 - acc: 0.8326 - val_loss: 0.4351 - val_acc: 0.8830\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 28/100\n",
        " - 1s - loss: 0.4740 - acc: 0.8319 - val_loss: 0.4096 - val_acc: 0.8857\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 29/100\n",
        " - 1s - loss: 0.4510 - acc: 0.8391 - val_loss: 0.3852 - val_acc: 0.8874\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 30/100\n",
        " - 1s - loss: 0.4221 - acc: 0.8511 - val_loss: 0.3651 - val_acc: 0.8961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 31/100\n",
        " - 1s - loss: 0.4013 - acc: 0.8576 - val_loss: 0.3452 - val_acc: 0.8999\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 32/100\n",
        " - 1s - loss: 0.3746 - acc: 0.8663 - val_loss: 0.3284 - val_acc: 0.9053\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 33/100\n",
        " - 1s - loss: 0.3624 - acc: 0.8732 - val_loss: 0.3142 - val_acc: 0.9070\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 34/100\n",
        " - 1s - loss: 0.3449 - acc: 0.8770 - val_loss: 0.3001 - val_acc: 0.9081\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 35/100\n",
        " - 1s - loss: 0.3330 - acc: 0.8792 - val_loss: 0.2881 - val_acc: 0.9097\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 36/100\n",
        " - 1s - loss: 0.3194 - acc: 0.8897 - val_loss: 0.2769 - val_acc: 0.9157\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 37/100\n",
        " - 1s - loss: 0.3082 - acc: 0.8896 - val_loss: 0.2662 - val_acc: 0.9162\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 38/100\n",
        " - 1s - loss: 0.2970 - acc: 0.8946 - val_loss: 0.2568 - val_acc: 0.9173\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 39/100\n",
        " - 1s - loss: 0.2872 - acc: 0.9006 - val_loss: 0.2485 - val_acc: 0.9178\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 40/100\n",
        " - 1s - loss: 0.2761 - acc: 0.9019 - val_loss: 0.2403 - val_acc: 0.9184\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 41/100\n",
        " - 1s - loss: 0.2700 - acc: 0.9062 - val_loss: 0.2332 - val_acc: 0.9195\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 42/100\n",
        " - 1s - loss: 0.2572 - acc: 0.9088 - val_loss: 0.2264 - val_acc: 0.9222\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 43/100\n",
        " - 1s - loss: 0.2517 - acc: 0.9100 - val_loss: 0.2200 - val_acc: 0.9206\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 44/100\n",
        " - 1s - loss: 0.2443 - acc: 0.9159 - val_loss: 0.2135 - val_acc: 0.9233\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 45/100\n",
        " - 1s - loss: 0.2382 - acc: 0.9153 - val_loss: 0.2078 - val_acc: 0.9233\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 46/100\n",
        " - 1s - loss: 0.2343 - acc: 0.9184 - val_loss: 0.2024 - val_acc: 0.9255\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 47/100\n",
        " - 1s - loss: 0.2274 - acc: 0.9178 - val_loss: 0.1982 - val_acc: 0.9238\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 48/100\n",
        " - 1s - loss: 0.2249 - acc: 0.9182 - val_loss: 0.1942 - val_acc: 0.9255\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 49/100\n",
        " - 1s - loss: 0.2139 - acc: 0.9251 - val_loss: 0.1886 - val_acc: 0.9255\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 50/100\n",
        " - 1s - loss: 0.2132 - acc: 0.9233 - val_loss: 0.1848 - val_acc: 0.9266\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 51/100\n",
        " - 1s - loss: 0.2031 - acc: 0.9249 - val_loss: 0.1805 - val_acc: 0.9260\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 52/100\n",
        " - 1s - loss: 0.2030 - acc: 0.9264 - val_loss: 0.1776 - val_acc: 0.9276\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 53/100\n",
        " - 1s - loss: 0.1969 - acc: 0.9307 - val_loss: 0.1739 - val_acc: 0.9282\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 54/100\n",
        " - 1s - loss: 0.1947 - acc: 0.9302 - val_loss: 0.1702 - val_acc: 0.9304\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 55/100\n",
        " - 1s - loss: 0.1896 - acc: 0.9298 - val_loss: 0.1673 - val_acc: 0.9304\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 56/100\n",
        " - 1s - loss: 0.1836 - acc: 0.9314 - val_loss: 0.1638 - val_acc: 0.9314\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 57/100\n",
        " - 1s - loss: 0.1830 - acc: 0.9327 - val_loss: 0.1625 - val_acc: 0.9314\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 58/100\n",
        " - 1s - loss: 0.1806 - acc: 0.9347 - val_loss: 0.1583 - val_acc: 0.9353\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 59/100\n",
        " - 1s - loss: 0.1756 - acc: 0.9385 - val_loss: 0.1563 - val_acc: 0.9342\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 60/100\n",
        " - 1s - loss: 0.1732 - acc: 0.9374 - val_loss: 0.1545 - val_acc: 0.9353\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 61/100\n",
        " - 1s - loss: 0.1726 - acc: 0.9362 - val_loss: 0.1513 - val_acc: 0.9380\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 62/100\n",
        " - 1s - loss: 0.1702 - acc: 0.9365 - val_loss: 0.1492 - val_acc: 0.9391\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 63/100\n",
        " - 1s - loss: 0.1635 - acc: 0.9380 - val_loss: 0.1479 - val_acc: 0.9385\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 64/100\n",
        " - 1s - loss: 0.1611 - acc: 0.9414 - val_loss: 0.1451 - val_acc: 0.9418\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 65/100\n",
        " - 1s - loss: 0.1598 - acc: 0.9389 - val_loss: 0.1431 - val_acc: 0.9407\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 66/100\n",
        " - 1s - loss: 0.1571 - acc: 0.9418 - val_loss: 0.1411 - val_acc: 0.9412\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 67/100\n",
        " - 1s - loss: 0.1579 - acc: 0.9411 - val_loss: 0.1394 - val_acc: 0.9450\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 68/100\n",
        " - 1s - loss: 0.1543 - acc: 0.9431 - val_loss: 0.1374 - val_acc: 0.9445\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 69/100\n",
        " - 1s - loss: 0.1530 - acc: 0.9411 - val_loss: 0.1358 - val_acc: 0.9456\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 70/100\n",
        " - 1s - loss: 0.1514 - acc: 0.9423 - val_loss: 0.1343 - val_acc: 0.9483\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 71/100\n",
        " - 1s - loss: 0.1510 - acc: 0.9429 - val_loss: 0.1333 - val_acc: 0.9489\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 72/100\n",
        " - 1s - loss: 0.1498 - acc: 0.9407 - val_loss: 0.1320 - val_acc: 0.9505\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 73/100\n",
        " - 1s - loss: 0.1479 - acc: 0.9432 - val_loss: 0.1307 - val_acc: 0.9461\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 74/100\n",
        " - 1s - loss: 0.1449 - acc: 0.9436 - val_loss: 0.1294 - val_acc: 0.9461\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 75/100\n",
        " - 1s - loss: 0.1418 - acc: 0.9441 - val_loss: 0.1287 - val_acc: 0.9483\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 76/100\n",
        " - 1s - loss: 0.1412 - acc: 0.9465 - val_loss: 0.1270 - val_acc: 0.9467\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 77/100\n",
        " - 1s - loss: 0.1413 - acc: 0.9463 - val_loss: 0.1261 - val_acc: 0.9478\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 78/100\n",
        " - 1s - loss: 0.1392 - acc: 0.9454 - val_loss: 0.1253 - val_acc: 0.9467\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 79/100\n",
        " - 1s - loss: 0.1385 - acc: 0.9476 - val_loss: 0.1240 - val_acc: 0.9494\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 80/100\n",
        " - 1s - loss: 0.1376 - acc: 0.9476 - val_loss: 0.1228 - val_acc: 0.9483\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 81/100\n",
        " - 1s - loss: 0.1387 - acc: 0.9463 - val_loss: 0.1230 - val_acc: 0.9472\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 82/100\n",
        " - 1s - loss: 0.1349 - acc: 0.9465 - val_loss: 0.1214 - val_acc: 0.9483\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 83/100\n",
        " - 1s - loss: 0.1365 - acc: 0.9469 - val_loss: 0.1208 - val_acc: 0.9527\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 84/100\n",
        " - 1s - loss: 0.1329 - acc: 0.9476 - val_loss: 0.1199 - val_acc: 0.9489\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 85/100\n",
        " - 1s - loss: 0.1327 - acc: 0.9483 - val_loss: 0.1193 - val_acc: 0.9494\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 86/100\n",
        " - 1s - loss: 0.1313 - acc: 0.9499 - val_loss: 0.1187 - val_acc: 0.9538\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 87/100\n",
        " - 1s - loss: 0.1307 - acc: 0.9494 - val_loss: 0.1178 - val_acc: 0.9499\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 88/100\n",
        " - 1s - loss: 0.1307 - acc: 0.9494 - val_loss: 0.1172 - val_acc: 0.9527\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 89/100\n",
        " - 1s - loss: 0.1289 - acc: 0.9492 - val_loss: 0.1166 - val_acc: 0.9554\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 90/100\n",
        " - 1s - loss: 0.1279 - acc: 0.9503 - val_loss: 0.1159 - val_acc: 0.9499\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 91/100\n",
        " - 1s - loss: 0.1281 - acc: 0.9467 - val_loss: 0.1154 - val_acc: 0.9499\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 92/100\n",
        " - 1s - loss: 0.1273 - acc: 0.9498 - val_loss: 0.1149 - val_acc: 0.9548\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 93/100\n",
        " - 1s - loss: 0.1280 - acc: 0.9469 - val_loss: 0.1142 - val_acc: 0.9548\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 94/100\n",
        " - 1s - loss: 0.1240 - acc: 0.9519 - val_loss: 0.1139 - val_acc: 0.9505\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 95/100\n",
        " - 1s - loss: 0.1264 - acc: 0.9503 - val_loss: 0.1136 - val_acc: 0.9538\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 96/100\n",
        " - 1s - loss: 0.1252 - acc: 0.9509 - val_loss: 0.1131 - val_acc: 0.9510\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 97/100\n",
        " - 1s - loss: 0.1235 - acc: 0.9521 - val_loss: 0.1128 - val_acc: 0.9516\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 98/100\n",
        " - 1s - loss: 0.1253 - acc: 0.9490 - val_loss: 0.1132 - val_acc: 0.9554\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 99/100\n",
        " - 1s - loss: 0.1222 - acc: 0.9530 - val_loss: 0.1121 - val_acc: 0.9521\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 100/100\n",
        " - 1s - loss: 0.1219 - acc: 0.9525 - val_loss: 0.1119 - val_acc: 0.9516\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This module tests the above creatd CNN model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[loss,acc]=model.evaluate(test_data,y_test)\n",
      "print(loss,acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  32/2947 [..............................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 448/2947 [===>..........................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 896/2947 [========>.....................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1344/2947 [============>.................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1792/2947 [=================>............] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2112/2947 [====================>.........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2464/2947 [========================>.....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2784/2947 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2947/2947 [==============================] - 0s 142us/step\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.21826243139853974, 0.9124533423820834)\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the training accuracy and loss"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(history.history['acc'],'r-',history.history['val_acc'],'b-')\n",
      "plt.xlabel('Iterations')\n",
      "plt.ylabel('Accuracy')\n",
      "plt.legend(['train','validation'],loc='bottom right')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'History' object has no attribute 'history'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-64-cbcdf91cb459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bottom right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'history'"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(history.history['loss'],'r-',history.history['val_loss'],'b-')\n",
      "plt.xlabel('Iterations')\n",
      "plt.ylabel('Loss')\n",
      "plt.legend(['train','validation'],loc='bottom right')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f99c04c79d0>"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Recurrent Neural Network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This module train a RNN for the same task."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# RNN Train\n",
      "from keras.layers import LSTM,RNN\n",
      "\n",
      "history=History()\n",
      "\n",
      "model=Sequential()\n",
      "model.add(LSTM(units=128,activation='sigmoid',input_shape=(time_steps,channels),dropout=0.3))\n",
      "model.add(Dense(6,activation='softmax'))\n",
      "\n",
      "print(model.summary())\n",
      "rmsprop=keras.optimizers.RMSprop(lr=0.0001)\n",
      "adam=keras.optimizers.Adam(lr=0.0001)\n",
      "model.compile(optimizer=rmsprop,loss='categorical_crossentropy',metrics=['accuracy'])\n",
      "# history=model.fit(x_train,y_train,epochs=100,batch_size=batch,validation_data=(x_val,y_val),verbose=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "lstm_17 (LSTM)               (None, 128)               70656     \n",
        "_________________________________________________________________\n",
        "dense_16 (Dense)             (None, 6)                 774       \n",
        "=================================================================\n",
        "Total params: 71,430\n",
        "Trainable params: 71,430\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the training accuracy and loss"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(history.history['acc'],'r-',history.history['val_acc'],'b-')\n",
      "plt.xlabel('Iterations')\n",
      "plt.ylabel('Accuracy')\n",
      "plt.legend(['train','validation'],loc='bottom right')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(history.history['loss'],'r-',history.history['val_loss'],'b-')\n",
      "plt.xlabel('Iterations')\n",
      "plt.ylabel('Loss')\n",
      "plt.legend(['train','validation'],loc='bottom right')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[loss,acc]=model.evaluate(test_data,y_test)\n",
      "print(loss,acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  32/2947 [..............................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 128/2947 [>.............................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 224/2947 [=>............................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 288/2947 [=>............................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 352/2947 [==>...........................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 416/2947 [===>..........................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 480/2947 [===>..........................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 544/2947 [====>.........................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 608/2947 [=====>........................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 672/2947 [=====>........................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 736/2947 [======>.......................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 800/2947 [=======>......................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 864/2947 [=======>......................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 928/2947 [========>.....................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 992/2947 [=========>....................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1056/2947 [=========>....................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1120/2947 [==========>...................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1184/2947 [===========>..................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1248/2947 [===========>..................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1312/2947 [============>.................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1376/2947 [=============>................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1440/2947 [=============>................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1504/2947 [==============>...............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1568/2947 [==============>...............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1632/2947 [===============>..............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1696/2947 [================>.............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1760/2947 [================>.............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1824/2947 [=================>............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1888/2947 [==================>...........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1952/2947 [==================>...........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2016/2947 [===================>..........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2080/2947 [====================>.........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2144/2947 [====================>.........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2208/2947 [=====================>........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2272/2947 [======================>.......] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2336/2947 [======================>.......] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2400/2947 [=======================>......] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2464/2947 [========================>.....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2528/2947 [========================>.....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2592/2947 [=========================>....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2656/2947 [==========================>...] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2720/2947 [==========================>...] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2784/2947 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2848/2947 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2912/2947 [============================>.] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2947/2947 [==============================] - 3s 899us/step\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.7648019703275113, 0.6973193077706142)\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This module tests the above created RNN model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Multi-layer Perceptron"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This module train a standard MLP with just one hidden layer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reading and storing data\n",
      "path=\"UCI HAR Dataset/UCI HAR Dataset/\"\n",
      "features=[x for x in listdir(path+\"train/Inertial Signals\") if '~' not in x]\n",
      "features1=[x for x in listdir(path+\"test/Inertial Signals\") if '~' not in x]\n",
      "cols=features+[\"Category\"]\n",
      "\n",
      "y_train=np.loadtxt(path+\"train/y_train.txt\").reshape((7352,1))-1\n",
      "y_test=np.loadtxt(path+\"test/y_test.txt\").reshape((2947,1))-1\n",
      "\n",
      "x_train=[]\n",
      "x_test=[]\n",
      "\n",
      "for i in range(len(features)):\n",
      "    print(i)\n",
      "    vals=np.loadtxt(path+'train/Inertial Signals/'+features[i])\n",
      "    vals1=np.loadtxt(path+'test/Inertial Signals/'+features1[i])\n",
      "    if i==0:\n",
      "        x_train=vals\n",
      "        x_test=vals1\n",
      "        \n",
      "    else:\n",
      "        x_train=np.hstack((x_train,vals))\n",
      "        x_test=np.hstack((x_test,vals1))\n",
      "\n",
      "# Normalize data        \n",
      "x_train=(x_train-np.mean(x_train,axis=0))/np.std(x_train,axis=0)\n",
      "x_test=(x_test-np.mean(x_test,axis=0))/np.std(x_test,axis=0)\n",
      "\n",
      "# Stratified train test split    \n",
      "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,stratify=y_train,random_state=123)    \n",
      "        \n",
      "x_train=x_train.reshape((x_train.shape[0],9,x_train.shape[1]/9))\n",
      "x_val=x_val.reshape((x_val.shape[0],9,x_val.shape[1]/9))\n",
      "x_test=x_test.reshape((x_test.shape[0],9,x_test.shape[1]/9))\n",
      "\n",
      "np.save('X_train',x_train,allow_pickle=False)\n",
      "np.save('X_val',x_val,allow_pickle=False)\n",
      "np.save('X_test',x_test,allow_pickle=False)\n",
      "np.save('Y_train',y_train,allow_pickle=False)\n",
      "np.save('Y_val',y_val,allow_pickle=False)\n",
      "np.save('Y_test',y_test,allow_pickle=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MLP\n",
      "\n",
      "from keras.utils import to_categorical\n",
      "from keras.layers import Dense,Dropout,Conv1D,BatchNormalization,MaxPool1D,Flatten\n",
      "from keras.models import Sequential\n",
      "\n",
      "# Load data\n",
      "x_train,y_train=np.load('X_train.npy',allow_pickle=False),np.load('Y_train.npy',allow_pickle=False)\n",
      "x_val,y_val=np.load('X_val.npy',allow_pickle=False),np.load('Y_val.npy',allow_pickle=False)\n",
      "x_test,y_test=np.load('X_test.npy',allow_pickle=False),np.load('Y_test.npy',allow_pickle=False)\n",
      "\n",
      "# Getting the data in required format\n",
      "mlp_x_train=x_train.reshape((x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
      "mlp_x_val=x_val.reshape((x_val.shape[0],x_val.shape[1]*x_val.shape[2]))\n",
      "mlp_x_test=x_test.reshape((x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
      "\n",
      "# One hot encoding of class labels\n",
      "y_train=to_categorical(y_train)\n",
      "y_val=to_categorical(y_val)\n",
      "y_test=to_categorical(y_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# MLP train\n",
      "model=Sequential()\n",
      "model.add(Dense(1024,activation='relu',input_shape=(128*9,)))\n",
      "model.add(Dropout(0.5))\n",
      "model.add(Dense(6,activation='softmax'))\n",
      "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
      "print(model.summary())\n",
      "model.fit(mlp_x_train,y_train,batch_size=64,epochs=10,verbose=2,validation_data=(mlp_x_val,y_val),shuffle=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# MLP test\n",
      "[test_loss,test_acc]=model.evaluate(mlp_x_test,y_test)\n",
      "print(test_loss,test_acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}